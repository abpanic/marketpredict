{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93987d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(left, right)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:131\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     result \u001b[38;5;241m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'NoneType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m c_date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m c_px \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNifty50.csv columns not recognized. Expected Date & Close-like column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m n50_qret \u001b[38;5;241m=\u001b[39m daily_to_quarter_ret(n50, c_date, c_px)\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnifty_qret\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# MIDCAP 100\u001b[39;00m\n\u001b[0;32m     64\u001b[0m mid \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(f_mid)\n",
      "Cell \u001b[1;32mIn[1], line 40\u001b[0m, in \u001b[0;36mdaily_to_quarter_ret\u001b[1;34m(df, date_col, price_col)\u001b[0m\n\u001b[0;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m _ensure_datetime(df, date_col)\u001b[38;5;241m.\u001b[39mset_index(date_col)\n\u001b[0;32m     39\u001b[0m q_price \u001b[38;5;241m=\u001b[39m df[price_col]\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlast()\n\u001b[1;32m---> 40\u001b[0m q_ret   \u001b[38;5;241m=\u001b[39m q_price\u001b[38;5;241m.\u001b[39mpct_change()\u001b[38;5;241m.\u001b[39mrename(price_col \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_qret\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_ret\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12161\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[1;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[0;32m  12159\u001b[0m shifted \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mshift(periods\u001b[38;5;241m=\u001b[39mperiods, freq\u001b[38;5;241m=\u001b[39mfreq, axis\u001b[38;5;241m=\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  12160\u001b[0m \u001b[38;5;66;03m# Unsupported left operand type for / (\"Self\")\u001b[39;00m\n\u001b[1;32m> 12161\u001b[0m rs \u001b[38;5;241m=\u001b[39m data \u001b[38;5;241m/\u001b[39m shifted \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m  12162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  12163\u001b[0m     \u001b[38;5;66;03m# Shift method is implemented differently when freq is not None\u001b[39;00m\n\u001b[0;32m  12164\u001b[0m     \u001b[38;5;66;03m# We want to restore the original index\u001b[39;00m\n\u001b[0;32m  12165\u001b[0m     rs \u001b[38;5;241m=\u001b[39m rs\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mrs\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mduplicated()]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__truediv__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__truediv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39mtruediv)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:227\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m         result \u001b[38;5;241m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 163\u001b[0m         result[mask] \u001b[38;5;241m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) Imports & folders\n",
    "# =========================\n",
    "import pandas as pd, numpy as np, warnings, re\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RAW  = Path('.')            # adjust if files live elsewhere\n",
    "PROC = Path('./processed'); PROC.mkdir(exist_ok=True)\n",
    "\n",
    "# Filenames you uploaded (adjust names if your casing differs)\n",
    "f_rain = RAW/'AnnualRainfall.csv'\n",
    "f_cpi  = RAW/'India_CPIMonthly_Jan_2013_to_Jun_2025.csv'\n",
    "f_gdp  = RAW/'india_gdp_quarterly_2010_2025_imf_ifs.csv'\n",
    "f_n50  = RAW/'Nifty50.csv'\n",
    "f_mid  = RAW/'NIFTYMidcap100.csv'\n",
    "f_repo = RAW/'RepoRate.csv'       # OPTIONAL: only if you later add one\n",
    "\n",
    "# =========================\n",
    "# 1) Helpers\n",
    "# =========================\n",
    "def _first_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns: return c\n",
    "    # fuzzy match\n",
    "    for c in df.columns:\n",
    "        for k in candidates:\n",
    "            if k.lower() in c.lower(): return c\n",
    "    return None\n",
    "\n",
    "def _ensure_datetime(df, col):\n",
    "    if not np.issubdtype(df[col].dtype, np.datetime64):\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def daily_to_quarter_ret(df, date_col, price_col):\n",
    "    df = df[[date_col, price_col]].dropna().sort_values(date_col)\n",
    "    df = _ensure_datetime(df, date_col)\n",
    "    df[price_col] = (\n",
    "        df[price_col].astype(str)\n",
    "        .str.replace(',', '', regex=False)\n",
    "        .str.replace('(', '-', regex=False)\n",
    "        .str.replace(')', '', regex=False)\n",
    "        .str.strip()\n",
    "        .replace({'': np.nan, 'None': np.nan})\n",
    "        .astype(float)\n",
    "    )\n",
    "    df = df.set_index(date_col)\n",
    "    q_price = df[price_col].resample('Q').last()\n",
    "    q_ret   = q_price.pct_change().rename(price_col + '_qret')\n",
    "    return q_ret\n",
    "\n",
    "def monthly_to_quarter(series_monthly, how='mean'):\n",
    "    if how == 'mean':\n",
    "        return series_monthly.resample('Q').mean()\n",
    "    return series_monthly.resample('Q').last()\n",
    "\n",
    "def yoy_from_monthly(series):\n",
    "    \"\"\"Compute YoY % change for a monthly index/value series.\"\"\"\n",
    "    return series.pct_change(12) * 100.0\n",
    "\n",
    "# =========================\n",
    "# 2) Index prices -> quarterly returns\n",
    "# =========================\n",
    "# NIFTY 50\n",
    "n50 = pd.read_csv(f_n50)\n",
    "c_date = _first_col(n50, ['Date','date','Time'])\n",
    "c_px   = _first_col(n50, ['Close','Adj Close','Price','Close Price','Value'])\n",
    "if c_date is None or c_px is None:\n",
    "    raise ValueError(\"Nifty50.csv columns not recognized. Expected Date & Close-like column.\")\n",
    "n50_qret = daily_to_quarter_ret(n50, c_date, c_px).rename('nifty_qret')\n",
    "\n",
    "# MIDCAP 100\n",
    "mid = pd.read_csv(f_mid)\n",
    "c_date_m = _first_col(mid, ['Date','date','Time'])\n",
    "c_px_m   = _first_col(mid, ['Close','Adj Close','Price','Close Price','Value'])\n",
    "if c_date_m is None or c_px_m is None:\n",
    "    raise ValueError(\"NIFTYMidcap100.csv columns not recognized. Expected Date & Close-like column.\")\n",
    "mid_qret = daily_to_quarter_ret(mid, c_date_m, c_px_m).rename('midcap_qret')\n",
    "\n",
    "# Excess return for quarter t\n",
    "excess_q = (mid_qret - n50_qret).rename('excess_ret')\n",
    "\n",
    "# =========================\n",
    "# 3) Rainfall anomaly (annual -> quarterly)\n",
    "# =========================\n",
    "rain = pd.read_csv(f_rain)\n",
    "# try to find year & anomaly columns\n",
    "c_year = _first_col(rain, ['Year','year','YYYY'])\n",
    "c_anom = _first_col(rain, ['Anomaly','Anomaly_%','Anomaly %','Rainfall Anomaly'])\n",
    "if c_year is None or c_anom is None:\n",
    "    raise ValueError(\"AnnualRainfall.csv must contain Year & Anomaly columns.\")\n",
    "rain = rain[[c_year, c_anom]].dropna()\n",
    "rain.columns = ['Year','rain_anom']\n",
    "# place anomaly at Sept 30 of that monsoon year; then ffill within year\n",
    "rain_idx = pd.to_datetime(rain['Year'].astype(int).astype(str) + '-09-30')\n",
    "rain_q = pd.Series(rain['rain_anom'].values, index=rain_idx).resample('Q').ffill()\n",
    "rain_q = rain_q.rename('rain_anom')\n",
    "\n",
    "# =========================\n",
    "# 4) CPI monthly -> CPI YoY -> quarterly\n",
    "# =========================\n",
    "cpi = pd.read_csv(f_cpi)\n",
    "c_date = _first_col(cpi, ['Date','date','Month','month','Period'])\n",
    "c_val  = _first_col(cpi, ['Index','CPI','Value','CPI Index','cpi'])\n",
    "if c_date is None or c_val is None:\n",
    "    raise ValueError(\"India_CPIMonthly*.csv must have Date & CPI value columns.\")\n",
    "cpi = _ensure_datetime(cpi, c_date).sort_values(c_date)\n",
    "cpi_m = cpi.set_index(c_date)[c_val].astype(float).rename('cpi_index')\n",
    "cpi_yoy_m = yoy_from_monthly(cpi_m).rename('cpi_yoy_m')\n",
    "cpi_yoy_q = monthly_to_quarter(cpi_yoy_m, how='mean').rename('cpi_yoy')\n",
    "\n",
    "# =========================\n",
    "# 5) GDP quarterly (YoY % preferred)\n",
    "# =========================\n",
    "gdp = pd.read_csv(f_gdp)\n",
    "c_date = _first_col(gdp, ['Date','date','Quarter','quarter','Period'])\n",
    "c_yoy  = _first_col(gdp, ['YoY','GDP_YoY','gdp_yoy','Growth','Growth YoY'])\n",
    "c_lvl  = _first_col(gdp, ['GDP','Value','gdp_sa','gdp'])\n",
    "if c_date is None:\n",
    "    raise ValueError(\"GDP csv must have a Date/Quarter column.\")\n",
    "gdp = _ensure_datetime(gdp, c_date).sort_values(c_date)\n",
    "\n",
    "if c_yoy is not None:\n",
    "    gdp_q = gdp.set_index(c_date)[c_yoy].astype(float).rename('gdp_yoy')\n",
    "elif c_lvl is not None:\n",
    "    # compute yoy if levels provided (assumes quarterly level series)\n",
    "    gdp_q = (gdp.set_index(c_date)[c_lvl].astype(float)\n",
    "             .pct_change(4) * 100.0).rename('gdp_yoy')\n",
    "else:\n",
    "    raise ValueError(\"GDP file must have either a YoY% column or a level column to compute YoY.\")\n",
    "\n",
    "# =========================\n",
    "# 6) OPTIONAL: Repo rate daily/point-in-time -> quarterly Δ\n",
    "# =========================\n",
    "if f_repo.exists():\n",
    "    repo = pd.read_csv(f_repo)\n",
    "    c_date = _first_col(repo, ['Date','date','Period'])\n",
    "    c_rate = _first_col(repo, ['Repo','Rate','Repo Rate','Policy Rate'])\n",
    "    repo = _ensure_datetime(repo, c_date).sort_values(c_date)\n",
    "    repo_q = repo.set_index(c_date)[c_rate].astype(float).resample('Q').last().rename('repo')\n",
    "    repo_chg_q = (repo_q.diff()*100).rename('repo_chg_bps')  # if rate in %, convert Δ to bps\n",
    "else:\n",
    "    repo_chg_q = pd.Series(dtype=float, name='repo_chg_bps')  # empty; handled later\n",
    "\n",
    "# =========================\n",
    "# 7) Align to common quarterly index & build features\n",
    "# =========================\n",
    "# Common quarterly index = intersection across main series\n",
    "qdf = pd.concat(\n",
    "    [excess_q.rename('excess_ret'),\n",
    "     mid_qret.rename('midcap_ret'),\n",
    "     n50_qret.rename('nifty_ret'),\n",
    "     rain_q, cpi_yoy_q, gdp_q, repo_chg_q],\n",
    "    axis=1\n",
    ").dropna(how='any')\n",
    "\n",
    "# Features (lagged 1Q):\n",
    "qdf['ret_prev_q']    = qdf['midcap_ret'].shift(1)\n",
    "qdf['rain_anom_lag'] = qdf['rain_anom'].shift(1)\n",
    "qdf['cpi_yoy_lag']   = qdf['cpi_yoy'].shift(1)\n",
    "qdf['gdp_yoy_lag']   = qdf['gdp_yoy'].shift(1)\n",
    "if 'repo_chg_bps' in qdf.columns:\n",
    "    qdf['repo_chg_lag'] = qdf['repo_chg_bps'].shift(1)\n",
    "\n",
    "# Target (excess return next quarter)\n",
    "qdf['excess_next_q'] = qdf['excess_ret'].shift(-1)\n",
    "\n",
    "# Policy-amplifier interaction (if repo present)\n",
    "if 'repo_chg_lag' in qdf.columns:\n",
    "    qdf['rain_repo_int'] = qdf['rain_anom_lag'] * qdf['repo_chg_lag']\n",
    "\n",
    "# Clean NA rows created by shifting\n",
    "qdf = qdf.dropna().copy()\n",
    "\n",
    "# =========================\n",
    "# 8) Sanity checks & save\n",
    "# =========================\n",
    "print(\"Quarterly rows:\", len(qdf), \"| Range:\", qdf.index.min().date(), \"→\", qdf.index.max().date())\n",
    "print(qdf.filter(['excess_ret','excess_next_q','ret_prev_q','rain_anom_lag','cpi_yoy_lag','gdp_yoy_lag']).head(8))\n",
    "\n",
    "qdf.to_parquet(PROC/'quarterly_features.parquet')\n",
    "qdf.to_csv(PROC/'quarterly_features.csv')\n",
    "\n",
    "# Small dictionary describing columns (handy for your slide)\n",
    "data_dict = {\n",
    "  'excess_ret': 'Midcap100_qret - Nifty50_qret (quarter t)',\n",
    "  'excess_next_q': 'Excess return in quarter t+1 (prediction target)',\n",
    "  'ret_prev_q': 'Midcap100 return in t-1',\n",
    "  'rain_anom_lag': 'All-India monsoon rainfall anomaly (t-1, %)',\n",
    "  'cpi_yoy_lag': 'CPI YoY (t-1, %)',\n",
    "  'gdp_yoy_lag': 'Real GDP YoY (t-1, %)',\n",
    "  'repo_chg_lag': 'Repo change in bps (t-1) [if provided]',\n",
    "  'rain_repo_int': 'Interaction rain_anom_lag × repo_chg_lag [if provided]'\n",
    "}\n",
    "pd.Series(data_dict).to_csv(PROC/'data_dictionary.csv')\n",
    "print(\"\\nSaved:\", (PROC/'quarterly_features.parquet').resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55314bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baseline vs Enriched (RQ-1) ---\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "X_base = qdf[['ret_prev_q']]\n",
    "y      = qdf['excess_next_q']\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def cv_pred(maker, X):\n",
    "    y_true, y_pred = [], []\n",
    "    for tr, te in tscv.split(X):\n",
    "        mdl = maker(); mdl.fit(X.iloc[tr], y.iloc[tr])\n",
    "        y_pred.extend(mdl.predict(X.iloc[te])); y_true.extend(y.iloc[te])\n",
    "    return np.array(y_true), np.array(y_pred)\n",
    "\n",
    "y_t, y_p = cv_pred(lambda: ElasticNetCV(cv=3), X_base)\n",
    "print(\"Baseline  R²:\", r2_score(y_t, y_p), \"MAE:\", mean_absolute_error(y_t, y_p))\n",
    "\n",
    "feat_cols = ['ret_prev_q','rain_anom_lag','cpi_yoy_lag','gdp_yoy_lag']\n",
    "if 'repo_chg_lag' in qdf.columns: feat_cols.append('repo_chg_lag')\n",
    "X_en = qdf[feat_cols]\n",
    "\n",
    "y_t2, y_p2 = cv_pred(lambda: LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=3), X_en)\n",
    "print(\"Enriched  R²:\", r2_score(y_t2, y_p2), \"MAE:\", mean_absolute_error(y_t2, y_p2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RQ-2 Good vs Poor monsoon ---\n",
    "from scipy.stats import ttest_ind, ks_2samp\n",
    "good = qdf.loc[qdf['rain_anom_lag'] >= 4,  'excess_next_q']\n",
    "poor = qdf.loc[qdf['rain_anom_lag'] <= -4, 'excess_next_q']\n",
    "print(\"t-test:\", ttest_ind(good, poor, equal_var=False))\n",
    "print(\"KS    :\", ks_2samp(good, poor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490d0584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RQ-3 Rain → GDP lead-lag ---\n",
    "import statsmodels.api as sm\n",
    "# align GDP on same index\n",
    "gdp_y = qdf['gdp_yoy_lag'].shift(-1)  # GDP_{t+1}\n",
    "X = sm.add_constant(qdf['rain_anom_lag'])\n",
    "res = sm.OLS(gdp_y.dropna(), X.loc[gdp_y.dropna().index]).fit()\n",
    "print(res.summary())\n",
    "\n",
    "# engineered feature & re-run enriched model with gdp_pred_from_rain\n",
    "qdf['gdp_pred_from_rain'] = (res.params['const'] + res.params['rain_anom_lag']*qdf['rain_anom_lag'])\n",
    "feat_cols2 = feat_cols + ['gdp_pred_from_rain']\n",
    "y_t3, y_p3 = cv_pred(lambda: LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=3), qdf[feat_cols2])\n",
    "print(\"Enriched+Rain→GDP  R²:\", r2_score(y_t3, y_p3), \"MAE:\", mean_absolute_error(y_t3, y_p3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ac813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RQ-4 Policy Amplifier (if repo available) ---\n",
    "if 'repo_chg_lag' in qdf.columns:\n",
    "    qdf['rain_repo_int'] = qdf['rain_anom_lag'] * qdf['repo_chg_lag']\n",
    "    Xint = sm.add_constant(qdf[['rain_anom_lag','repo_chg_lag','rain_repo_int']])\n",
    "    res_int = sm.OLS(qdf['excess_next_q'], Xint).fit()\n",
    "    print(res_int.summary())\n",
    "\n",
    "    feat_cols3 = feat_cols2 + ['rain_repo_int'] if 'gdp_pred_from_rain' in qdf.columns else feat_cols + ['rain_repo_int']\n",
    "    y_t4, y_p4 = cv_pred(lambda: LGBMRegressor(n_estimators=300, learning_rate=0.05, max_depth=3), qdf[feat_cols3])\n",
    "    print(\"Enriched + interaction  R²:\", r2_score(y_t4, y_p4), \"MAE:\", mean_absolute_error(y_t4, y_p4))\n",
    "else:\n",
    "    print(\"Repo rate file not provided; skipping RQ-4.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
