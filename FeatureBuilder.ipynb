{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8427b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a18325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Imports, engine check, folders\n",
    "# =========================\n",
    "import pandas as pd, numpy as np, warnings, re\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Require a Parquet engine ---\n",
    "try:\n",
    "    import pyarrow  # noqa: F401\n",
    "    PARQUET_ENGINE = \"pyarrow\"\n",
    "except ImportError:\n",
    "    try:\n",
    "        import fastparquet  # noqa: F401\n",
    "        PARQUET_ENGINE = \"fastparquet\"\n",
    "    except ImportError as e:\n",
    "        raise ImportError(\n",
    "            \"Parquet output is required but no engine is installed.\\n\"\n",
    "            \"Install one of:\\n\"\n",
    "            \"  pip install pyarrow\\n\"\n",
    "            \"    or\\n\"\n",
    "            \"  pip install fastparquet\"\n",
    "        ) from e\n",
    "\n",
    "RAW  = Path('./raw')            # change if your files are elsewhere\n",
    "PROC = Path('./processed'); PROC.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ef49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust column picker (case-insensitive, partial matches allowed)\n",
    "def pick(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns: return c\n",
    "    for c in df.columns:\n",
    "        for k in candidates:\n",
    "            if k.lower() in c.lower(): return c\n",
    "    return None\n",
    "\n",
    "# Smart date parser: chooses the best of multiple formats by coverage\n",
    "from dateutil import parser as _dateparser\n",
    "\n",
    "def smart_parse_dates(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str)\n",
    "    attempts = []\n",
    "    attempts.append(('infer', pd.to_datetime(s, errors='coerce')))\n",
    "    attempts.append(('dayfirst', pd.to_datetime(s, errors='coerce', dayfirst=True)))\n",
    "    fmts = ['%d-%b-%Y','%d-%b-%y','%d/%m/%Y','%m/%d/%Y','%Y-%m-%d','%b %d, %Y','%d %b %Y','%b %Y','%m-%Y']\n",
    "    for fmt in fmts:\n",
    "        attempts.append((fmt, pd.to_datetime(s, format=fmt, errors='coerce')))\n",
    "    def score(dt):\n",
    "        ok = dt.dropna()\n",
    "        if ok.empty: return (0,0,0)\n",
    "        ser = pd.Series(1, index=ok).sort_index()\n",
    "        by_year_months = ser.groupby(ser.index.year).apply(lambda x: len(pd.Index(x.index.month).unique()))\n",
    "        med_months = int(by_year_months.median()) if len(by_year_months) else 0\n",
    "        return (len(ok), med_months, len(pd.Index(ok.dt.month).unique()))\n",
    "    best_name, best_dt, best_score = max([(n,d,score(d)) for n,d in attempts], key=lambda t: t[2])\n",
    "    print(f\"[smart_parse_dates] picked: {best_name} | parsed={best_score[0]} | median months/yr={best_score[1]} | unique months={best_score[2]}\")\n",
    "    return best_dt\n",
    "\n",
    "def parse_dates_in_df(df, date_col='Date'):\n",
    "    out = df.copy()\n",
    "    out[date_col] = smart_parse_dates(out[date_col])\n",
    "    out = out.dropna(subset=[date_col]).sort_values(date_col)\n",
    "    return out\n",
    "\n",
    "def _parse_investing_prices(df, date_col='Date', price_col='Price'):\n",
    "    out = parse_dates_in_df(df, date_col=date_col)\n",
    "    out[price_col] = pd.to_numeric(out[price_col].astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
    "    out = out.dropna(subset=[price_col])\n",
    "    return out[[date_col, price_col]]\n",
    "\n",
    "def investing_to_quarter_ret(df, date_col='Date', price_col='Price'):\n",
    "    df2 = _parse_investing_prices(df, date_col, price_col)\n",
    "    q_end_price = df2.set_index(date_col)[price_col].resample('Q').last()\n",
    "    return q_end_price.pct_change()\n",
    "\n",
    "def monthly_to_quarter(series, how='mean'):\n",
    "    return series.resample('Q').mean() if how=='mean' else series.resample('Q').last()\n",
    "\n",
    "def yoy_from_monthly(series):\n",
    "    return series.pct_change(12) * 100.0\n",
    "\n",
    "def check_monthly_coverage(df, date_col='Date', label='series'):\n",
    "    dates = smart_parse_dates(df[date_col]).dropna()\n",
    "    ser = pd.Series(1, index=dates).sort_index()\n",
    "    months_per_year = ser.groupby(ser.index.year).apply(lambda s: sorted(pd.Index(s.index.month).unique()))\n",
    "    print(f\"[{label}] Months present per year:\")\n",
    "    for y, months in months_per_year.items():\n",
    "        print(f\"  {y}: {months}\")\n",
    "    q_counts = ser.resample('Q').size()\n",
    "    miss = q_counts[q_counts == 0]\n",
    "    if len(miss) > 0:\n",
    "        print(f\"[{label}] ⚠ Missing {len(miss)} quarter(s) with zero rows — resample will yield NaNs.\")\n",
    "    else:\n",
    "        print(f\"[{label}] ✅ At least one row in every quarter.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "108ee50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[smart_parse_dates] picked: infer | parsed=188 | median months/yr=12 | unique months=12\n",
      "[NIFTY 50] Months present per year:\n",
      "  2010: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2011: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2012: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2013: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2014: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2015: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2016: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2017: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2018: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2019: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2020: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2021: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2022: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2023: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2024: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2025: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[NIFTY 50] ✅ At least one row in every quarter.\n",
      "[smart_parse_dates] picked: infer | parsed=188 | median months/yr=12 | unique months=12\n",
      "[NIFTY Midcap 100] Months present per year:\n",
      "  2010: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2011: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2012: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2013: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2014: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2015: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2016: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2017: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2018: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2019: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2020: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2021: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2022: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2023: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2024: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  2025: [1, 2, 3, 4, 5, 6, 7, 8]\n",
      "[NIFTY Midcap 100] ✅ At least one row in every quarter.\n",
      "[smart_parse_dates] picked: infer | parsed=188 | median months/yr=12 | unique months=12\n",
      "[smart_parse_dates] picked: infer | parsed=188 | median months/yr=12 | unique months=12\n",
      "Index quarterly points (excess_ret): 62\n"
     ]
    }
   ],
   "source": [
    "# Ensure files exist in ./raw\n",
    "n50_raw = pd.read_csv(RAW/'Nifty50.csv')\n",
    "mid_raw = pd.read_csv(RAW/'NIFTYMidcap100.csv')\n",
    "\n",
    "# Quick coverage QA (helps catch wrong date parsing or partial exports)\n",
    "check_monthly_coverage(n50_raw, 'Date', 'NIFTY 50')\n",
    "check_monthly_coverage(mid_raw, 'Date', 'NIFTY Midcap 100')\n",
    "\n",
    "nifty_qret  = investing_to_quarter_ret(n50_raw).rename('nifty_qret')\n",
    "midcap_qret = investing_to_quarter_ret(mid_raw).rename('midcap_qret')\n",
    "excess_ret  = (midcap_qret - nifty_qret).rename('excess_ret')\n",
    "\n",
    "print(\"Index quarterly points (excess_ret):\", excess_ret.dropna().shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPI monthly to YoY% to quarterly mean\n",
    "cpi = pd.read_csv(RAW/'CPI_Monthly_Jan_2013_to_Jun_2025.csv')  # <- file name you uploaded\n",
    "c_date = pick(cpi, ['DATE','Date','Month','Period'])           # will choose 'DATE'\n",
    "c_val  = pick(cpi, ['CPI','Index','Value','CPI_COMBINED_BASE2012_100'])  # will choose 'CPI_COMBINED_BASE2012_100'\n",
    "\n",
    "cpi = parse_dates_in_df(cpi, c_date)   # smart date parser picked \"infer\" in my check\n",
    "cpi_m = cpi.set_index(c_date)[c_val].astype(float).rename('cpi_index')\n",
    "\n",
    "# YoY requires 12 months of history, so the first 12 rows will be NaN (expected)\n",
    "cpi_yoy_m = yoy_from_monthly(cpi_m).rename('cpi_yoy_m')\n",
    "\n",
    "# Aggregate to quarterly (mean of three months)\n",
    "cpi_yoy_q = monthly_to_quarter(cpi_yoy_m, how='mean').rename('cpi_yoy')\n",
    "print(\"CPI monthly points:\", cpi_m.shape[0], \"| CPI YoY monthly (non-NaN):\", cpi_yoy_m.dropna().shape[0])\n",
    "print(\"CPI quarterly points:\", cpi_yoy_q.dropna().shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
